{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvslogov+jWxlau0G6cW0N"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mount drive and access proper directory to place and read the files"
      ],
      "metadata": {
        "id": "mr3Ze6Jhy6wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/Colab\\ Notebooks/AI/Assignment/\n",
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "B3z7ufVxy9Iv",
        "outputId": "58568778-73ee-44cc-d9fc-5b0a07a5d315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab Notebooks/AI/Assignment\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/AI/Assignment'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the relevant libraries (os, shutil, random) in order to manipulate files into the correct folders, and choose a train/test distribution with random samples"
      ],
      "metadata": {
        "id": "ee-Ozm84zBhr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FhcC8hNysTh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define where to read the images from, where they will go, the training/test ratio, and finally a mapping for the abbreviations used in the filenames versus the actual emotions that will be used in the FER Classification Model"
      ],
      "metadata": {
        "id": "lI7ClxM7zqKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_PATH = \"./JAFFE/Original\"\n",
        "OUTPUT_PATH = \"./JAFFE/Converted\"\n",
        "\n",
        "# 70% Training, 30% Testing\n",
        "TRAIN_RATIO=0.7\n",
        "\n",
        "# Mapping from JAFFE abbreviations to emotion names\n",
        "EMOTION_MAP = {\n",
        "    \"AN\": \"Anger\",\n",
        "    \"DI\": \"Disgust\",\n",
        "    \"FE\": \"Fear\",\n",
        "    \"HA\": \"Happiness\",\n",
        "    \"NE\": \"Neutral\",\n",
        "    \"SA\": \"Sadness\",\n",
        "    \"SU\": \"Surprise\"\n",
        "}"
      ],
      "metadata": {
        "id": "84uDFhZDzOFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the relevant folders for training and testing, and get all the image files (JAFFE uses .tiff).\n",
        "\n",
        "Then, shuffle the files around so that it is somewhat random if the notebook is ever ran more than once.\n",
        "\n",
        "Finally, perform the split by deciding where the \"split point\" should be (split_index) and using list manipulation"
      ],
      "metadata": {
        "id": "wHSQHCS-1DLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure output folders exist\n",
        "train_dir = os.path.join(OUTPUT_PATH, \"Training\")\n",
        "test_dir = os.path.join(OUTPUT_PATH, \"Test\")\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Get all image filenames\n",
        "files = [f for f in os.listdir(INPUT_PATH) if f.lower().endswith((\".tiff\"))]\n",
        "\n",
        "# Shuffle using random library to make sure the split of testing/training is not\n",
        "# always the same or similar whenever this nb is ran\n",
        "random.shuffle(files)\n",
        "\n",
        "# Perform the split into training and testing\n",
        "split_index = int(len(files) * TRAIN_RATIO)\n",
        "train_files = files[:split_index]\n",
        "test_files = files[split_index:]\n",
        "\n",
        "print(\"Length of files \", len(files))\n",
        "print(\"Train files \", len(train_files))\n",
        "print(\"Test files \", len(test_files))"
      ],
      "metadata": {
        "id": "8m6GXNkqzhiW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6e995f0-e2b1-401e-c636-ac7e8c990e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of files  213\n",
            "Train files  149\n",
            "Test files  64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the training and testing folders have been created, it's necessary to make the emotion folders inside of them. Split up the name by parts using a period delimiter. Then use the `EMOTION_MAP` to determine what the name of each emotion folder should be."
      ],
      "metadata": {
        "id": "wE76DLEi2chG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_file_list(file_list, destination):\n",
        "    # Every image is being considered\n",
        "    for filename in file_list:\n",
        "        # Example filename: \"KA.AN1.39.tiff\" --> split on every \".\"\n",
        "        parts = filename.split(\".\")\n",
        "\n",
        "        if len(parts) < 2:\n",
        "            malformed_filename_count = malformed_filename_count + 1\n",
        "            continue\n",
        "\n",
        "        # Remove the number of the pose, e.g.: 'AN1' --> 'AN'\n",
        "        emotion_abbreviation = parts[1][:2]\n",
        "\n",
        "        # Map the abbreviation to the actual emotion name. Skip invalid\n",
        "        # emotions not in the list or Disgust -- more information in report\n",
        "        emotion = EMOTION_MAP.get(emotion_abbreviation)\n",
        "        if emotion is None or emotion == \"Disgust\":\n",
        "            continue\n",
        "\n",
        "        # Create subfolder for this emotion, don't overwrite existing ones\n",
        "        emotion_folder = os.path.join(destination, emotion)\n",
        "        os.makedirs(emotion_folder, exist_ok=True)\n",
        "\n",
        "        # Copy the file into the converted folder instead of moving it\n",
        "        # to maintain the original structure\n",
        "        src_path = os.path.join(INPUT_PATH, filename)\n",
        "        dst_path = os.path.join(emotion_folder, filename)\n",
        "\n",
        "        shutil.copy(src_path, dst_path)"
      ],
      "metadata": {
        "id": "_AeRIjmw1yz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output the status of the conversion as it's happeninng"
      ],
      "metadata": {
        "id": "O1qfsYT03ODM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Processing the Training set..\")\n",
        "process_file_list(train_files, train_dir)\n",
        "\n",
        "print(\"Processing the Test set..\")\n",
        "process_file_list(test_files, test_dir)\n",
        "\n",
        "print(\"Complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IO0uhb0zlme",
        "outputId": "08928bd4-cb19-4d7a-be7e-be7391ab7785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing the Training set..\n",
            "Processing the Test set..\n",
            "Complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output the number of each, this can be used to confirm the split worked correctly"
      ],
      "metadata": {
        "id": "Yo5i9SdU3QzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training images: {len(train_files)}\")\n",
        "print(f\"Test images: {len(test_files)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw8sE1gD3R0u",
        "outputId": "06f221a8-dd19-4df2-fa2b-cd4b755a1edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images: 149\n",
            "Test images: 64\n"
          ]
        }
      ]
    }
  ]
}